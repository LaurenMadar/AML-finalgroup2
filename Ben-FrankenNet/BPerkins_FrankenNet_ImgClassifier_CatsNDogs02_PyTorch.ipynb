{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9YN0lR6rQky"
   },
   "source": [
    "# PyTorch Implementation of Cats n'Dogs\n",
    "*Created by Ben Perkins*\n",
    "\n",
    "---\n",
    "*Notable References:*\n",
    "\n",
    "https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864\n",
    "\n",
    "https://wandb.ai/authors/ayusht/reports/Dropout-in-PyTorch-An-Example--VmlldzoxNTgwOTE\n",
    "\n",
    "----\n",
    "\n",
    "I created this notebook to attempt to classify the Cats n' Dogs images with PyTorch. It includes:\n",
    "* an alternative approach to creating the task datasets;\n",
    "* **Data augmentation** steps to gain more accuracy in predictions;\n",
    "* implementation of manual calculation of the image **mean and standard deviation** to pass the correct data to the `Normalize()` transform step. This step will remove the `mean_pixel` value from the data.\n",
    "* **Object-Oriented Neural Network model**, adapted and augmented from the *Fritz.AI* website shown above;\n",
    "* Use of **Sequential API** within the model to order the flow of the neural network.\n",
    "\n",
    "The model was able to reach consistent 75% test accuracy, but so far not able to overcome what seems like overfitting. It starts with a 32x32 image size, which may be the best it can do for that resolution. Although train accuracy reached up to 98%, with a loss of around .05%, the test accuracy stagnated at around 75%.\n",
    "\n",
    "`Epoch 9, Train Accuracy: 0.7727535963058472 , TrainLoss: 0.4672778248786926 , Test Accuracy: 0.7463377118110657, Best Accuracy: 0.7463377118110657`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aVTpZIqSPMAw"
   },
   "outputs": [],
   "source": [
    "# Import general modules\n",
    "import os\n",
    "import glob\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import warnings\n",
    "\n",
    "# PyTorch Modules\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ReLU\n",
    "from torch import nn, optim\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.utils\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TNf1vRLrQRW8"
   },
   "outputs": [],
   "source": [
    "def extract_tar(file, path):\n",
    "    \"\"\"\n",
    "    function to extract tar.gz files to specified location\n",
    "    \n",
    "    Args:\n",
    "        file (str): path where the file is located\n",
    "        path (str): path where you want to extract\n",
    "    \"\"\"\n",
    "    with tarfile.open(file) as tar:\n",
    "        files_extracted = 0\n",
    "        for member in tqdm(tar.getmembers()):\n",
    "            if os.path.isfile(path + member.name[1:]):\n",
    "                continue\n",
    "            else:\n",
    "                tar.extract(member, path)\n",
    "                files_extracted += 1\n",
    "        tar.close()\n",
    "        if files_extracted < 3:\n",
    "            print('Files already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrqLEk9LSPdo",
    "outputId": "0fb02f24-c2da-4805-ff45-a526d17886ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "dcc5f0ea4124440faa0115c54777906a",
      "d40eddf4d23b4b0f9ccf859c74b9bae2",
      "51c2d10530f24ae8bd99d1c9ceb7f44b",
      "84ea5d8fce5c4f8fa81712a7cc37414b",
      "f43d2ba415f043eeb6c8b92efc394917",
      "3a272e1569f446b9b231681c2d27655b",
      "4d7df574f0d149b89981678cb848c179",
      "d0f4050f872946beb5eb4bbc40af4a0f"
     ]
    },
    "id": "iDkdquyBSTHi",
    "outputId": "3f3b41db-c7ba-4f03-f475-8727158b7a26"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc5f0ea4124440faa0115c54777906a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25936.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/content/drive/MyDrive/Colab Notebooks/CatsNDogs/data/cadod/'\n",
    "\n",
    "extract_tar('/content/drive/MyDrive/Colab Notebooks/CatsNDogs/data/cadod.tar.gz', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FIi374qDScHo"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CatsNDogs/cadod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "ATFdQOlgSvyZ",
    "outputId": "c7da5d73-c777-41c8-cbf3-ff48f255588d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Source</th>\n",
       "      <th>LabelName</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>XMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMin</th>\n",
       "      <th>YMax</th>\n",
       "      <th>IsOccluded</th>\n",
       "      <th>IsTruncated</th>\n",
       "      <th>IsGroupOf</th>\n",
       "      <th>IsDepiction</th>\n",
       "      <th>IsInside</th>\n",
       "      <th>XClick1X</th>\n",
       "      <th>XClick2X</th>\n",
       "      <th>XClick3X</th>\n",
       "      <th>XClick4X</th>\n",
       "      <th>XClick1Y</th>\n",
       "      <th>XClick2Y</th>\n",
       "      <th>XClick3Y</th>\n",
       "      <th>XClick4Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000b9fcba019d36</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636250</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.748750</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.661667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000cb13febe0138</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410882</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>0.999062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005a9520eb22c19</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.226296</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>0.305942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006303f02219b07</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508594</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375294</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.998824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00064d23bf997652</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.906183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678038</td>\n",
       "      <td>0.906183</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.424286</td>\n",
       "      <td>0.694286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID  Source  LabelName  ...  XClick2Y  XClick3Y  XClick4Y\n",
       "0  0000b9fcba019d36  xclick  /m/0bt9lr  ...  0.506667  0.998333  0.661667\n",
       "1  0000cb13febe0138  xclick  /m/0bt9lr  ...  0.410882  0.999062  0.999062\n",
       "2  0005a9520eb22c19  xclick  /m/0bt9lr  ...  0.226296  0.998736  0.305942\n",
       "3  0006303f02219b07  xclick  /m/0bt9lr  ...  0.375294  0.720000  0.998824\n",
       "4  00064d23bf997652  xclick  /m/0bt9lr  ...  0.370000  0.424286  0.694286\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDHBL_Itisgz",
    "outputId": "31c75260-2a5a-4c90-d54a-96997ae5904a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/m/0bt9lr', '/m/01yrx'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LabelName.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eJ9g4kTq8ZI"
   },
   "source": [
    "# Create train_csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d8GRH7hclbef"
   },
   "outputs": [],
   "source": [
    "def label_img(row):\n",
    "    if row['LabelName'] == '/m/0bt9lr':\n",
    "        return 1\n",
    "    if row['LabelName'] == '/m/01yrx':\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "MOQB96dZmzhC",
    "outputId": "b366ca09-1a3d-41b4-8560-c916920775f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Source</th>\n",
       "      <th>LabelName</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>XMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMin</th>\n",
       "      <th>YMax</th>\n",
       "      <th>IsOccluded</th>\n",
       "      <th>IsTruncated</th>\n",
       "      <th>IsGroupOf</th>\n",
       "      <th>IsDepiction</th>\n",
       "      <th>IsInside</th>\n",
       "      <th>XClick1X</th>\n",
       "      <th>XClick2X</th>\n",
       "      <th>XClick3X</th>\n",
       "      <th>XClick4X</th>\n",
       "      <th>XClick1Y</th>\n",
       "      <th>XClick2Y</th>\n",
       "      <th>XClick3Y</th>\n",
       "      <th>XClick4Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000b9fcba019d36</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636250</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.748750</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.661667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000cb13febe0138</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410882</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>0.999062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005a9520eb22c19</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.226296</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>0.305942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006303f02219b07</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508594</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375294</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.998824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00064d23bf997652</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.906183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678038</td>\n",
       "      <td>0.906183</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.424286</td>\n",
       "      <td>0.694286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID  Source  LabelName  ...  XClick2Y  XClick3Y  XClick4Y\n",
       "0  0000b9fcba019d36  xclick  /m/0bt9lr  ...  0.506667  0.998333  0.661667\n",
       "1  0000cb13febe0138  xclick  /m/0bt9lr  ...  0.410882  0.999062  0.999062\n",
       "2  0005a9520eb22c19  xclick  /m/0bt9lr  ...  0.226296  0.998736  0.305942\n",
       "3  0006303f02219b07  xclick  /m/0bt9lr  ...  0.375294  0.720000  0.998824\n",
       "4  00064d23bf997652  xclick  /m/0bt9lr  ...  0.370000  0.424286  0.694286\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyWY3_aSm_Zp",
    "outputId": "14a04749-dfd3-4f01-b7c6-8cb1cc35e19e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['cdlabel'] = df2.apply(lambda row: label_img(row), axis=1)\n",
    "df2['cdlabel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4leTrZLYtldb"
   },
   "outputs": [],
   "source": [
    "df3 = pd.concat([df2['ImageID'], df2['cdlabel']], axis=1, keys=['ImageID', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "lIPm_hAXsqCY",
    "outputId": "1c402aa6-6a12-4f31-ed01-ecc9f2de27f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000b9fcba019d36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000cb13febe0138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005a9520eb22c19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006303f02219b07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00064d23bf997652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID  label\n",
       "0  0000b9fcba019d36      1\n",
       "1  0000cb13febe0138      1\n",
       "2  0005a9520eb22c19      1\n",
       "3  0006303f02219b07      1\n",
       "4  00064d23bf997652      1"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXu0dqWuZJjP",
    "outputId": "cbe49faf-dcfe-4b25-c785-5d83a6b0121d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sy8R3z5_5NmW"
   },
   "outputs": [],
   "source": [
    "df3.to_csv(r'train_csv.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vqJPDWySw9l"
   },
   "source": [
    "# PyTorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caDi8295az9W",
    "outputId": "e43e93ad-e2eb-4723-f905-678970dd8c09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Configure device for GPU or CPU depending on what is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RoBZjYN6taY"
   },
   "source": [
    "# Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KYHtgFM1jL8c"
   },
   "outputs": [],
   "source": [
    "train_file = 'train_csv.csv'\n",
    "img_dir = '/content/drive/MyDrive/Colab Notebooks/CatsNDogs/data/cadod/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eNWk1VyA6yEU"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(annotation_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.annotations.iloc[index, 0]\n",
    "        img = Image.open(os.path.join(self.root_dir, img_id+'.jpg')).convert(\"RGB\")\n",
    "        y_label = torch.tensor(self.annotations.iloc[index, 1])\n",
    "       \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, y_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAbhKaV8YxU2"
   },
   "source": [
    "# Create dataset to calculate the Mean and Standard Deviation for Normailze()\n",
    "*This ultimately went unused, but I did experiment with Normalize() to subtract the `mean_pixel` from the image tensors.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OP-a98QqpGLm"
   },
   "outputs": [],
   "source": [
    "calctransform = transforms.Compose(([        # transforms.Compose - removed\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PS-PSyrYiqDi"
   },
   "outputs": [],
   "source": [
    "calcdata = CustomDataset(root_dir=img_dir, annotation_file='train_csv.csv', transform=calctransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObN9u3wPo5_t",
    "outputId": "e78cbd1a-f21d-442d-9fd3-0cd99058e848"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3608, 0.3843, 0.5412,  ..., 0.9961, 0.9961, 0.9961],\n",
       "         [0.4078, 0.4902, 0.5765,  ..., 0.9961, 0.9961, 0.9961],\n",
       "         [0.4863, 0.5373, 0.4118,  ..., 0.9961, 0.9961, 0.9961],\n",
       "         ...,\n",
       "         [0.6471, 0.5804, 0.3843,  ..., 0.9961, 0.9961, 0.9961],\n",
       "         [0.5765, 0.5294, 0.2941,  ..., 0.9647, 0.9608, 0.9804],\n",
       "         [0.4235, 0.3529, 0.2588,  ..., 0.9373, 0.9412, 0.9686]],\n",
       "\n",
       "        [[0.3608, 0.3843, 0.5373,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4039, 0.4902, 0.5725,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4824, 0.5333, 0.4078,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.6431, 0.5765, 0.3843,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5725, 0.5255, 0.2941,  ..., 0.9686, 0.9647, 0.9843],\n",
       "         [0.4196, 0.3490, 0.2588,  ..., 0.9451, 0.9412, 0.9725]],\n",
       "\n",
       "        [[0.3529, 0.3765, 0.5294,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.3961, 0.4824, 0.5647,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4745, 0.5255, 0.4000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.6353, 0.5686, 0.3765,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.5647, 0.5176, 0.2863,  ..., 0.9686, 0.9647, 0.9843],\n",
       "         [0.4118, 0.3412, 0.2549,  ..., 0.9412, 0.9412, 0.9725]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcdata[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1DJ1Hh02wDSd"
   },
   "outputs": [],
   "source": [
    "calcloader = DataLoader(\n",
    "    calcdata,\n",
    "    batch_size=10,\n",
    "    num_workers=1,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "for idx, (data, label) in enumerate(calcloader, 0):\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Rl7EwyKE0DM",
    "outputId": "4aa6b061-a8c9-42f1-d7ac-738cafc0fcaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of image tensors:  tensor([0.4708, 0.4266, 0.3788])\n",
      "Standard deviation of image tensors:  tensor([0.2201, 0.2147, 0.2091])\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of image tensors: \", mean)\n",
    "print(\"Standard deviation of image tensors: \", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GO-5DV4JZFoN"
   },
   "source": [
    "# Create datasets for use in model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "A_n_Gk7j0sLv"
   },
   "outputs": [],
   "source": [
    "# Initial data transformation to resized tensors\n",
    "init_transform = transforms.Compose(([        \n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.4708, 0.4266, 0.3788), (0.2201, 0.2147, 0.2091))\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zJPVO0Nkmv5X"
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "all_data = CustomDataset(root_dir=img_dir, annotation_file='train_csv.csv', transform=init_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "U1A1gsIL0yxx"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "num_train = int(len(all_data) * 0.8)\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(all_data, [num_train, len(all_data) - num_train])\n",
    "\n",
    "# Make Train Loader:\n",
    "train_dataloader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "                                  \n",
    "# Make test loader:\n",
    "test_dataloader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc3cDyUrzzgy"
   },
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "cKj1Xx_Dz7Q-"
   },
   "outputs": [],
   "source": [
    "class Unit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Unit, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, kernel_size=3, \n",
    "                              out_channels=out_channels, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        output = self.bn(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "class ImgNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ImgNet, self).__init__()\n",
    "\n",
    "         #Create 14 layers of the unit with max pooling in between\n",
    "        self.unit1 = Unit(in_channels=3,out_channels=32)\n",
    "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
    "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
    "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
    "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
    "        # self.unit7 = Unit(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit8 = Unit(in_channels=64, out_channels=128)\n",
    "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
    "        # self.unit11 = Unit(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit12 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
    "        # self.unit14 = Unit(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
    "        \n",
    "        #Add all the units into the Sequential layer in exact order\n",
    "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, \n",
    "                                 self.unit4, self.unit5, self.unit6, \n",
    "                                 self.pool2, self.unit8, \n",
    "                                 self.unit9, self.unit10, self.pool3,\n",
    "                                 self.unit12, self.unit13, self.avgpool)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.net(input)\n",
    "        output = output.view(-1,128)\n",
    "        output = self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88MBNzvRxYEO"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ndQUnoXExZ_B"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "\n",
    "model = ImgNet(num_classes=2)\n",
    "\n",
    "if cuda_avail:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001) # Need to try different lr values\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOqL5O1ogNCd",
    "outputId": "c3f9d620-8317-4d1b-c385-8de94a0aa4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit1.conv.weight \t torch.Size([32, 3, 3, 3])\n",
      "unit1.conv.bias \t torch.Size([32])\n",
      "unit1.bn.weight \t torch.Size([32])\n",
      "unit1.bn.bias \t torch.Size([32])\n",
      "unit2.conv.weight \t torch.Size([32, 32, 3, 3])\n",
      "unit2.conv.bias \t torch.Size([32])\n",
      "unit2.bn.weight \t torch.Size([32])\n",
      "unit2.bn.bias \t torch.Size([32])\n",
      "unit3.conv.weight \t torch.Size([32, 32, 3, 3])\n",
      "unit3.conv.bias \t torch.Size([32])\n",
      "unit3.bn.weight \t torch.Size([32])\n",
      "unit3.bn.bias \t torch.Size([32])\n",
      "unit4.conv.weight \t torch.Size([64, 32, 3, 3])\n",
      "unit4.conv.bias \t torch.Size([64])\n",
      "unit4.bn.weight \t torch.Size([64])\n",
      "unit4.bn.bias \t torch.Size([64])\n",
      "unit5.conv.weight \t torch.Size([64, 64, 3, 3])\n",
      "unit5.conv.bias \t torch.Size([64])\n",
      "unit5.bn.weight \t torch.Size([64])\n",
      "unit5.bn.bias \t torch.Size([64])\n",
      "unit6.conv.weight \t torch.Size([64, 64, 3, 3])\n",
      "unit6.conv.bias \t torch.Size([64])\n",
      "unit6.bn.weight \t torch.Size([64])\n",
      "unit6.bn.bias \t torch.Size([64])\n",
      "unit8.conv.weight \t torch.Size([128, 64, 3, 3])\n",
      "unit8.conv.bias \t torch.Size([128])\n",
      "unit8.bn.weight \t torch.Size([128])\n",
      "unit8.bn.bias \t torch.Size([128])\n",
      "unit9.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "unit9.conv.bias \t torch.Size([128])\n",
      "unit9.bn.weight \t torch.Size([128])\n",
      "unit9.bn.bias \t torch.Size([128])\n",
      "unit10.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "unit10.conv.bias \t torch.Size([128])\n",
      "unit10.bn.weight \t torch.Size([128])\n",
      "unit10.bn.bias \t torch.Size([128])\n",
      "unit12.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "unit12.conv.bias \t torch.Size([128])\n",
      "unit12.bn.weight \t torch.Size([128])\n",
      "unit12.bn.bias \t torch.Size([128])\n",
      "unit13.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "unit13.conv.bias \t torch.Size([128])\n",
      "unit13.bn.weight \t torch.Size([128])\n",
      "unit13.bn.bias \t torch.Size([128])\n",
      "fc.weight \t torch.Size([2, 128])\n",
      "fc.bias \t torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  print(name, '\\t', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXGNQXNjgTFH"
   },
   "outputs": [],
   "source": [
    "# Check for available GPU for modelNN:\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJUSANJXjAbq"
   },
   "source": [
    "**Maybe a learning rate adjuster??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "k-FXpPo-jFyd"
   },
   "outputs": [],
   "source": [
    "# https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864\n",
    "\n",
    "# # Create a learning rate adjustment function that divides the learning rate by 10 every 5 epochs\n",
    "# def adjust_learning_rate(epoch):\n",
    "#     lr = 0.001\n",
    "\n",
    "#     if epoch > 35:\n",
    "#         lr = lr / 1000000\n",
    "#     elif epoch > 30:\n",
    "#         lr = lr / 100000\n",
    "#     elif epoch > 25:\n",
    "#         lr = lr / 10000\n",
    "#     elif epoch > 20:\n",
    "#         lr = lr / 1000\n",
    "#     elif epoch > 15:\n",
    "#         lr = lr / 100\n",
    "#     elif epoch > 10:\n",
    "#         lr = lr / 10\n",
    "\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group[\"lr\"] = lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xccbVrhrlY4"
   },
   "source": [
    "### Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Mr3dpvTmrkCl"
   },
   "outputs": [],
   "source": [
    "def save_models(epoch):\n",
    "    torch.save(model.state_dict(), \"cadodModel_{}.model\".format(epoch))\n",
    "    print(\"Checkpoint saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "G1vNdqPxr6yO"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    for i, (images, labels) in enumerate(test_dataloader):\n",
    "\n",
    "        if cuda_avail:\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "\n",
    "        test_acc += torch.sum(prediction == labels.data)\n",
    "\n",
    "    test_acc = test_acc / 2594\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-SgHCKE4Zar"
   },
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "-vgtNp-Ky_O-"
   },
   "outputs": [],
   "source": [
    "# https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864\n",
    "\n",
    "def train(num_epochs):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            # Move images and labels to gpu if available\n",
    "            if cuda_avail:\n",
    "                images = Variable(images.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "\n",
    "            # Clear all accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Predict classes using images from the test set\n",
    "            outputs = model(images)\n",
    "            # Compute the loss based on the predictions and actual labels\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust parameters according to the computed gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.cuda().data * images.size(0)\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            \n",
    "            train_acc += torch.sum(prediction == labels.data)\n",
    "\n",
    "        # Call the learning rate adjustment function\n",
    "        # adjust_learning_rate(epoch)\n",
    "\n",
    "        # Compute the average acc and loss over all 10372 training images\n",
    "        train_acc = train_acc / num_train\n",
    "        train_loss = train_loss / num_train\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        test_acc = test()\n",
    "\n",
    "        # Save the model if the test acc is greater than our current best\n",
    "        if test_acc > best_acc:\n",
    "            save_models(epoch)\n",
    "            best_acc = test_acc\n",
    "\n",
    "        # Print the metrics\n",
    "        print(\"Epoch {}, Train Accuracy: {} , TrainLoss: {} , Test Accuracy: {}, Best Accuracy: {}\".format(epoch,\n",
    "                                                                                        train_acc,\n",
    "                                                                                        train_loss,\n",
    "                                                                                        test_acc,\n",
    "                                                                                        best_acc))\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlkNI8ag0Bz0"
   },
   "source": [
    "# Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bSPU0XQ0G8Z",
    "outputId": "1726fdda-4dc9-4173-e0c6-880839273ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved\n",
      "Epoch 0, Train Accuracy: 0.5468569397926331 , TrainLoss: 0.6885741949081421 , Test Accuracy: 0.5666923522949219, Best Accuracy: 0.5666923522949219\n",
      "Checkpoint saved\n",
      "Epoch 1, Train Accuracy: 0.6025838851928711 , TrainLoss: 0.6654961705207825 , Test Accuracy: 0.5767154693603516, Best Accuracy: 0.5767154693603516\n",
      "Epoch 2, Train Accuracy: 0.6386424899101257 , TrainLoss: 0.6384814381599426 , Test Accuracy: 0.5481880903244019, Best Accuracy: 0.5767154693603516\n",
      "Checkpoint saved\n",
      "Epoch 3, Train Accuracy: 0.667759358882904 , TrainLoss: 0.6104883551597595 , Test Accuracy: 0.6723207235336304, Best Accuracy: 0.6723207235336304\n",
      "Checkpoint saved\n",
      "Epoch 4, Train Accuracy: 0.6932125091552734 , TrainLoss: 0.5798431038856506 , Test Accuracy: 0.6838858723640442, Best Accuracy: 0.6838858723640442\n",
      "Epoch 5, Train Accuracy: 0.7147126793861389 , TrainLoss: 0.5567981004714966 , Test Accuracy: 0.6808018088340759, Best Accuracy: 0.6838858723640442\n",
      "Epoch 6, Train Accuracy: 0.7321635484695435 , TrainLoss: 0.5351565480232239 , Test Accuracy: 0.64957594871521, Best Accuracy: 0.6838858723640442\n",
      "Checkpoint saved\n",
      "Epoch 7, Train Accuracy: 0.7484574317932129 , TrainLoss: 0.5095189809799194 , Test Accuracy: 0.6939089894294739, Best Accuracy: 0.6939089894294739\n",
      "Checkpoint saved\n",
      "Epoch 8, Train Accuracy: 0.7388160824775696 , TrainLoss: 0.5184327960014343 , Test Accuracy: 0.7124132513999939, Best Accuracy: 0.7124132513999939\n",
      "Checkpoint saved\n",
      "Epoch 9, Train Accuracy: 0.7727535963058472 , TrainLoss: 0.4672778248786926 , Test Accuracy: 0.7463377118110657, Best Accuracy: 0.7463377118110657\n",
      "Epoch 10, Train Accuracy: 0.7796953320503235 , TrainLoss: 0.4507569372653961 , Test Accuracy: 0.7266769409179688, Best Accuracy: 0.7463377118110657\n",
      "Epoch 11, Train Accuracy: 0.7982067465782166 , TrainLoss: 0.42273956537246704 , Test Accuracy: 0.7197378277778625, Best Accuracy: 0.7463377118110657\n",
      "Epoch 12, Train Accuracy: 0.8227921724319458 , TrainLoss: 0.3873001039028168 , Test Accuracy: 0.7340015172958374, Best Accuracy: 0.7463377118110657\n",
      "Epoch 13, Train Accuracy: 0.8273235559463501 , TrainLoss: 0.3702605068683624 , Test Accuracy: 0.7336159944534302, Best Accuracy: 0.7463377118110657\n",
      "Epoch 14, Train Accuracy: 0.8564404249191284 , TrainLoss: 0.32928770780563354 , Test Accuracy: 0.7147262692451477, Best Accuracy: 0.7463377118110657\n",
      "Epoch 15, Train Accuracy: 0.8677207827568054 , TrainLoss: 0.304370254278183 , Test Accuracy: 0.7343870401382446, Best Accuracy: 0.7463377118110657\n",
      "Epoch 16, Train Accuracy: 0.8901851177215576 , TrainLoss: 0.2652280330657959 , Test Accuracy: 0.717810332775116, Best Accuracy: 0.7463377118110657\n",
      "Epoch 17, Train Accuracy: 0.8913421034812927 , TrainLoss: 0.2594973146915436 , Test Accuracy: 0.7232073545455933, Best Accuracy: 0.7463377118110657\n",
      "Epoch 18, Train Accuracy: 0.8967412710189819 , TrainLoss: 0.2467840611934662 , Test Accuracy: 0.7370855808258057, Best Accuracy: 0.7463377118110657\n",
      "Epoch 19, Train Accuracy: 0.9221944212913513 , TrainLoss: 0.19340674579143524 , Test Accuracy: 0.7266769409179688, Best Accuracy: 0.7463377118110657\n",
      "Epoch 20, Train Accuracy: 0.940609335899353 , TrainLoss: 0.14543691277503967 , Test Accuracy: 0.713955283164978, Best Accuracy: 0.7463377118110657\n",
      "Epoch 21, Train Accuracy: 0.9451407790184021 , TrainLoss: 0.13757754862308502 , Test Accuracy: 0.6638396382331848, Best Accuracy: 0.7463377118110657\n",
      "Epoch 22, Train Accuracy: 0.9516004920005798 , TrainLoss: 0.11705107241868973 , Test Accuracy: 0.7220508456230164, Best Accuracy: 0.7463377118110657\n",
      "Epoch 23, Train Accuracy: 0.9586386680603027 , TrainLoss: 0.10122182220220566 , Test Accuracy: 0.6788743138313293, Best Accuracy: 0.7463377118110657\n",
      "Epoch 24, Train Accuracy: 0.9691477417945862 , TrainLoss: 0.08316676318645477 , Test Accuracy: 0.7286044359207153, Best Accuracy: 0.7463377118110657\n",
      "Epoch 25, Train Accuracy: 0.9686656594276428 , TrainLoss: 0.08615244925022125 , Test Accuracy: 0.6626830697059631, Best Accuracy: 0.7463377118110657\n",
      "Epoch 26, Train Accuracy: 0.9696298241615295 , TrainLoss: 0.08023034781217575 , Test Accuracy: 0.7247493863105774, Best Accuracy: 0.7463377118110657\n",
      "Epoch 27, Train Accuracy: 0.9789819121360779 , TrainLoss: 0.058462053537368774 , Test Accuracy: 0.7193523049354553, Best Accuracy: 0.7463377118110657\n",
      "Epoch 28, Train Accuracy: 0.9693405628204346 , TrainLoss: 0.07803017646074295 , Test Accuracy: 0.7247493863105774, Best Accuracy: 0.7463377118110657\n",
      "Epoch 29, Train Accuracy: 0.9789819121360779 , TrainLoss: 0.05512441694736481 , Test Accuracy: 0.7235928773880005, Best Accuracy: 0.7463377118110657\n",
      "Epoch 30, Train Accuracy: 0.8917277455329895 , TrainLoss: 0.27243852615356445 , Test Accuracy: 0.7081726789474487, Best Accuracy: 0.7463377118110657\n",
      "Epoch 31, Train Accuracy: 0.976475179195404 , TrainLoss: 0.07098869979381561 , Test Accuracy: 0.7235928773880005, Best Accuracy: 0.7463377118110657\n",
      "Epoch 32, Train Accuracy: 0.9589279294013977 , TrainLoss: 0.1083630621433258 , Test Accuracy: 0.7239784002304077, Best Accuracy: 0.7463377118110657\n",
      "Epoch 33, Train Accuracy: 0.9813922643661499 , TrainLoss: 0.05376489460468292 , Test Accuracy: 0.7050886750221252, Best Accuracy: 0.7463377118110657\n",
      "Epoch 34, Train Accuracy: 0.9894909858703613 , TrainLoss: 0.03351413831114769 , Test Accuracy: 0.6480339169502258, Best Accuracy: 0.7463377118110657\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train(35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-a4wD2dzHwog"
   },
   "source": [
    "# Brief Discussion\n",
    "\n",
    "Test accuracy topped at about **75%** in most experiments. It would be interesting to try more measures. I tried `Dropout` but that seemed to make the testing loss erratic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwkta81uaKdu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "wexEbAmMjToN"
   ],
   "name": "BPerkins_FrankenNet-ImgClassifier_CatsNDogs02-PyTorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3a272e1569f446b9b231681c2d27655b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d7df574f0d149b89981678cb848c179": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51c2d10530f24ae8bd99d1c9ceb7f44b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a272e1569f446b9b231681c2d27655b",
      "max": 25936,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f43d2ba415f043eeb6c8b92efc394917",
      "value": 25936
     }
    },
    "84ea5d8fce5c4f8fa81712a7cc37414b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0f4050f872946beb5eb4bbc40af4a0f",
      "placeholder": "",
      "style": "IPY_MODEL_4d7df574f0d149b89981678cb848c179",
      "value": " 25936/25936 [05:49&lt;00:00, 74.25it/s]"
     }
    },
    "d0f4050f872946beb5eb4bbc40af4a0f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d40eddf4d23b4b0f9ccf859c74b9bae2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcc5f0ea4124440faa0115c54777906a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_51c2d10530f24ae8bd99d1c9ceb7f44b",
       "IPY_MODEL_84ea5d8fce5c4f8fa81712a7cc37414b"
      ],
      "layout": "IPY_MODEL_d40eddf4d23b4b0f9ccf859c74b9bae2"
     }
    },
    "f43d2ba415f043eeb6c8b92efc394917": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
